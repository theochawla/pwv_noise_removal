{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f808937f-adbc-4168-a20e-53129e02de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import ascii\n",
    "from pylab import *\n",
    "from astropy.table import Table, vstack\n",
    "import pandas as pd\n",
    "from expecto import get_spectrum\n",
    "from scipy.interpolate import RegularGridInterpolator as rgi\n",
    "from itertools import product\n",
    "from scipy.stats import binned_statistic\n",
    "#%run Interpolate.ipynb\n",
    "#%run GetSpectra.ipynb\n",
    "#%run Binning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a506992-c389-445d-b86c-f9662b42d2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthroughput of 0.4, swope is 1m in diameter, hole is .5m in diameter\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "calculates photon noise, normalized to 0. throughput and transmission are fractional values. Transmission is set up to be\n",
    "calculated over array of water content values (for pwv timeseries). \n",
    "\n",
    "Questions: how do we get initial photon count from the star from the flux? In practice I think we could get that value\n",
    "directly from Henrietta's CCD detectors, but how do we do it simulation?\n",
    "\n",
    "I guess if it's normalized, it's really calculting a percentage value and not actual changes in flux, and any flux values\n",
    "could be used.\n",
    "\n",
    "What units for exposure time? (pwv time series, each point is 1 minute) (needs to compare to flux, meausured in photons/sec)\n",
    "\n",
    "re-write in terms of gaussian\n",
    "\n",
    "after re-writing: I'm getting significantly different values from the gaussian and poisson distributions. It seems like \n",
    "poisson dist has much (orders of mag) larger std dev. Maybe I'm using the np version of the random generator wrong?\n",
    "I thought poisson std dev was supposed to decrease with point count, but it still seems large even with values of 10**14\n",
    "\n",
    "missing bin size, should be low resolution bin size\n",
    "\n",
    "Note: right now, bin sizes are in angstroms, since this is the unit that the hi-res flux comes with. Bin sizes are filtered\n",
    "from binning function to stacking to division_noise to photon_noise. bin sizes for 1.8-1.95 microns are about 180-190 A. \n",
    "'''\n",
    "\n",
    "def photon_noise(flux, bin_size, mirror_diameter = 100, exp_time = 60, throughput = .4):\n",
    "    \n",
    "    mirror_area = np.pi*((mirror_diameter/2)**2) - np.pi*((25)**2)\n",
    "    #print(\"mirror area:\"+str(mirror_area))\n",
    "    \n",
    "    #bin_size_array = [bin_array[1]-bin_array[0]]\n",
    "    '''\n",
    "    i=0\n",
    "    for n in bin_array:\n",
    "        if i == len(bin_array)-1:\n",
    "            break\n",
    "        bin_size2 = bin_array[i+1] - bin_array[i]\n",
    "        bin_size_array.append(bin_size2)\n",
    "        j+=1\n",
    "    '''\n",
    "    num_photons = flux*mirror_area*exp_time*throughput*bin_size\n",
    "    #print(\"num photons:\"+str(num_photons[0:10]))\n",
    "    noise_std_dev = 1/(num_photons**(1/2))\n",
    "    #print(\"noise std dev: \"+str(noise_std_dev))\n",
    "    \n",
    "    photon_noise_gaussian = np.random.normal(1, noise_std_dev, len(flux))\n",
    "    \n",
    "    return photon_noise_gaussian\n",
    "\n",
    "\n",
    "'''\n",
    "throughput of 0.4, swope is 1m in diameter, hole is .5m in diameter\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1942842-7d87-4c41-86d4-d069055f43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_pwv(v, c = 1e-7):\n",
    "\n",
    "    return c * v**-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb9fe2-a4cb-42b3-9b98-53c903ce6795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_correlation(separation):\n",
    "\n",
    "    return np.exp(-0.5*(separation/45)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5dc815-425c-48f9-a3c4-a61393850bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_spectrum(N, omega_max, M, timestamps, mean = 0, target = True, phase = None, separation = None):\n",
    "\n",
    "    delta_omega = omega_max / N\n",
    "    A_n = np.array([2 * np.sqrt(P_pwv(n * delta_omega + .00001) * delta_omega) for n in range(N + 1)])\n",
    "    A_n_zero = np.array([0 for n in range(N + 1, M)])\n",
    "    A_n = np.concatenate((A_n, A_n_zero))\n",
    "\n",
    "    \n",
    "    if target:\n",
    "        phi = np.random.uniform(0,2 * np.pi, M)\n",
    "        B_n = np.exp(1.0j*phi)\n",
    "        phase = B_n\n",
    "        pwv = np.real(np.fft.fft(A_n*B_n)/2)\n",
    "        \n",
    "        pwv += mean\n",
    "        pwv_delta_t = np.pi/omega_max\n",
    "        pwv_t = np.arange(0, M*pwv_delta_t, pwv_delta_t)/3600\n",
    "        binned_pwv, binned_pwv_t, _ = binned_statistic(pwv_t, pwv, bins = timestamps)\n",
    "        binned_pwv = np.insert(binned_pwv, 0, np.mean(binned_pwv))\n",
    "\n",
    "    else:\n",
    "        B_n = phase\n",
    "        phi = np.random.uniform(0, 2*np.pi, M)\n",
    "        C_n = A_n*angular_correlation(separation)\n",
    "        D_n = A_n*np.sqrt(1 - angular_correlation(separation)**2)\n",
    "        E_n = np.exp(1.0j*phi)\n",
    "        \n",
    "        pwv = np.real(np.fft.fft(C_n*B_n + D_n*E_n)/2)\n",
    "        \n",
    "        pwv += mean\n",
    "        \n",
    "        pwv_delta_t = np.pi/omega_max\n",
    "        pwv_t = np.arange(0, M*pwv_delta_t, pwv_delta_t)/3600\n",
    "        binned_pwv, binned_pwv_t, _ = binned_statistic(pwv_t, pwv, bins = timestamps)\n",
    "        binned_pwv = np.insert(binned_pwv, 0, np.mean(binned_pwv))\n",
    "\n",
    "\n",
    "    return binned_pwv_t, binned_pwv, phase, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6501df9-6f70-4b2d-8c0b-ebbdfba134ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    timestamps = np.linspace(0,10,1000) #time in hours\n",
    "    t, target_star_pwv, target_star_phase, target_star_mean = power_spectrum(12000, 1, 24000, timestamps, mean = 2)\n",
    "    t1, comparison_star_pwv, _, _ = power_spectrum(12000, 1, 24000, timestamps, mean = target_star_mean, target = False, phase = target_star_phase, separation = 25)\n",
    "\n",
    "    plt.plot(t, target_star_pwv)\n",
    "    plt.plot(t, comparison_star_pwv)\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae7005-4088-4cee-88b1-81c92ff9537b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b2f62-4e18-4225-b1d4-3dbc80d242df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
